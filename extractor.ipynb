{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries and Costants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "from lxml import etree\n",
    "import logging\n",
    "import re\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', force=True)\n",
    "\n",
    "SOURCES_DIR = 'sources/'\n",
    "EXTRACTION_DIR = 'extraction/'\n",
    "\n",
    "if not os.path.exists(EXTRACTION_DIR):\n",
    "    os.makedirs(f'./{EXTRACTION_DIR}', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def salva_dati_in_json(dati_estratti, article_id, extraction_path):\n",
    "    tabelle = dati_estratti\n",
    "    output_file_path = f\"{extraction_path}/{article_id}.json\"\n",
    "    os.makedirs(extraction_path, exist_ok=True)\n",
    "    with open(output_file_path, 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(tabelle, json_file, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estrai_dati_da_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    parser = etree.HTMLParser()\n",
    "    tree = etree.fromstring(content, parser)\n",
    "\n",
    "    tabelle = {}\n",
    "    table_counter = 0\n",
    "\n",
    "    figure_with_tables = tree.xpath('//figure[.//table]')\n",
    "\n",
    "    for figure in figure_with_tables:\n",
    "        try:\n",
    "            try:\n",
    "                table_id = figure.xpath(\"@id\")[0]\n",
    "            except:\n",
    "                table_id = figure.xpath('ancestor::div[2]/@id')[0]\n",
    "            table = figure.xpath('.//table')[0]\n",
    "            table_counter += 1\n",
    "            table_key = f\"id_table_{table_counter}\"\n",
    "\n",
    "            caption = figure.xpath('.//figcaption//text()')\n",
    "            caption_text = '' \n",
    "\n",
    "            if caption:\n",
    "                caption_text = ''.join([c.strip() for c in caption]).replace('  ', ' ')\n",
    "\n",
    "            dati_tabella = []\n",
    "            rows = table.xpath('.//tr[position()>1]')\n",
    "            for row in rows:\n",
    "                cols = row.xpath('.//td')\n",
    "                dati_row = [etree.tostring(col, encoding='unicode', method='html') for col in cols]\n",
    "                dati_tabella.append(dati_row)\n",
    "\n",
    "            references = tree.xpath(f\"//p[a/@href = '#{table_id}']\")\n",
    "            references_text = [ref.xpath('string(.)').replace('\\n', '').strip() for ref in references]   #elimina /n ma introduce spazi bianchi\n",
    "            \n",
    "            note_a_pie_di_pagina = []\n",
    "            footnotes = figure.xpath(\".//span[contains(@id, 'footnote') and contains(@class, 'ltx_text')]\")\n",
    "            for footnote in footnotes:\n",
    "                logging.info(f\"footnote found: {footnote} at table: {table_id}\")\n",
    "\n",
    "                footnote_text = \" \".join(footnote.xpath(\".//text()\")).strip()\n",
    "                if footnote_text and footnote_text != \" \":\n",
    "                    footnote_text = footnote_text.replace(\"\\n\", \" \")\n",
    "                    note_a_pie_di_pagina.append(footnote_text)\n",
    "\n",
    "            tabelle[table_key] = {\n",
    "                \"caption\": caption_text,\n",
    "                \"table\": dati_tabella,\n",
    "                \"footnotes\": note_a_pie_di_pagina,\n",
    "                \"references\": references_text,\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing figure in {file_path}: {e}\")\n",
    "            logging.error(f\"Figure content: {etree.tostring(figure, encoding='unicode', pretty_print=True)}\")\n",
    "        \n",
    "    return tabelle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Punto di lancio del codice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Itera attraverso i file nella cartella 'articoli' e estrae le tabelle, didascalie, note e riferimenti\n",
    "total_tables = 0\n",
    "total_captions = 0\n",
    "total_footnotes = 0\n",
    "total_references = 0\n",
    "articolo_counter = 0\n",
    "\n",
    "#questo é perché nel salvataggio dei file ho creato cartella articoli dentro a sources\n",
    "for filename in os.listdir(SOURCES_DIR):\n",
    "    file_path = os.path.join(SOURCES_DIR, filename)\n",
    "    article_id = filename.split('_')[2].replace('.html', '')  # Estrae l'ID dal nome del file (primo elemento prima del punto)\n",
    "\n",
    "    articolo_counter += 1  # Incrementa il contatore\n",
    "    logging.info(f\"Estraendo dati dall'articolo {articolo_counter}: {filename}...\")\n",
    "\n",
    "    # Estrai i dati dal file HTML\n",
    "    dati_estratti = estrai_dati_da_file(file_path)\n",
    "\n",
    "    # Update statistics counters\n",
    "    for table_data in dati_estratti.values():\n",
    "        total_tables += 1\n",
    "        if table_data[\"caption\"]:\n",
    "            total_captions += 1\n",
    "        total_footnotes += len(table_data[\"footnotes\"])\n",
    "        total_references += len(table_data[\"references\"])\n",
    "\n",
    "    # Salva i dati in JSON\n",
    "    salva_dati_in_json(dati_estratti, article_id, EXTRACTION_DIR)\n",
    "        \n",
    "# Print statistics\n",
    "logging.info(\"\\n--- Extraction Statistics ---\")\n",
    "logging.info(f\"Total Articles Processed: {articolo_counter}\")\n",
    "logging.info(f\"Total Tables Found: {total_tables}\")\n",
    "logging.info(f\"Total Captions Found: {total_captions}\")\n",
    "logging.info(f\"Total Footnotes Found: {total_footnotes}\")\n",
    "logging.info(f\"Total References Found: {total_references}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valutazione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numero di tabelle estratte sul numero di tabelle totali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    filepaths = os.listdir(SOURCES_DIR)\n",
    "    totale_html = 0\n",
    "    totale_json = 0\n",
    "    pattern = re.compile(r'[a-zA-Z]\\d+\\.T(\\d+)')\n",
    "\n",
    "    for filename in filepaths:\n",
    "        article_id = filename.split('_')[2].replace('.html', '')\n",
    "        json_filename = f\"{article_id}.json\"\n",
    "        json_filepath = os.path.join(EXTRACTION_DIR, json_filename)\n",
    "\n",
    "        with open(os.path.join(SOURCES_DIR, filename), 'r', encoding='utf-8') as file, open(json_filepath, 'r', encoding='utf-8') as json_file:\n",
    "            html_content = file.read()\n",
    "            soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "            ty_values = set()\n",
    "            for tag in soup.find_all(id=pattern):\n",
    "                match = pattern.search(tag['id'])\n",
    "                if match:\n",
    "                    ty_values.add(match.group())\n",
    "\n",
    "            json_data = json.load(json_file)\n",
    "            tables_in_html = len(ty_values)\n",
    "            tables_in_json = len(json_data)\n",
    "\n",
    "            totale_html += tables_in_html\n",
    "            totale_json += tables_in_json\n",
    "            if tables_in_json != tables_in_html:\n",
    "                logging.warning(f\"Found {tables_in_json}/{tables_in_html} tables (JSON/HTML) in {filename}\")\n",
    "            else:\n",
    "                logging.info(f\"Found: {tables_in_json}/{tables_in_html} tables (JSON/HTML) in {filename}\")\n",
    "\n",
    "    logging.info(f\"Found: {totale_json}/{totale_html} tables\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confrontando le tabelle estratte con l'xPath: `//figure[.//table]` con le tabelle trovate nell'html cercando gli `id` contenenti la lettera **T** seguita da un numero, notiamo che la nostra assunzione è errata. Questo perché non sempre le tabelle sono formattate tramite un tag `<table>`, ad esempio nell'articolo 2309.17288 nessuna delle tre tabelle presenti compare in un tag `<table>`. \\\n",
    "\\\n",
    "Abbiamo quindi trovato **1879** tabelle tramite l'xPath su un totale di **1914** tabelle  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Riscrivo l'estrazione con un nuovo xpath più preciso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estrai_dati_da_file_v2(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    parser = etree.HTMLParser()\n",
    "    tree = etree.fromstring(content, parser)\n",
    "\n",
    "    tabelle = {}\n",
    "    table_counter = 0\n",
    "\n",
    "    elements = tree.xpath('//*[starts-with(@id, \"S\") or starts-with(@id, \"A\")][contains(@id, \".T\") and contains(@class, \"ltx_table\")]')\n",
    "    for element in elements:\n",
    "        try:\n",
    "            table_counter += 1\n",
    "            table_id = element.attrib['id']\n",
    "            if element.tag != 'figure':\n",
    "                element = element.xpath('.//figure')[0]\n",
    "            table = element.xpath('.//*[contains(@class, \"ltx_tabular\")]')[0]\n",
    "            table_key = f\"id_table_{table_counter}\"\n",
    "            caption = element.xpath('.//figcaption[contains(@class, \"ltx_caption\")]/text()')\n",
    "            caption_text = ''\n",
    "\n",
    "            if caption:\n",
    "                caption_text = ''.join([c.strip() for c in caption]).replace('  ', ' ')\n",
    "            \n",
    "            rows = table.xpath('.//*[contains(@class, \"ltx_tr\")]')\n",
    "            dati_tabella = []\n",
    "            \n",
    "            for row in rows:\n",
    "                dati_tabella.append([etree.tostring(col, encoding='unicode', method='html',pretty_print=True) for col in row.xpath('.//*[contains(@class, \"ltx_td\")]')])\n",
    "            \n",
    "            references = tree.xpath(f\"//p[a/@href = '#{table_id}']\")\n",
    "            references_text = [ref.xpath('string(.)').replace('\\n', '').strip() for ref in references]   #elimina /n ma introduce spazi bianchi\n",
    "                \n",
    "            note_a_pie_di_pagina = []\n",
    "            footnotes = element.xpath(\".//span[contains(@id, 'footnote') and contains(@class, 'ltx_text')]\")\n",
    "            for footnote in footnotes:\n",
    "                footnote_text = \" \".join(footnote.xpath(\".//text()\")).strip()\n",
    "                if footnote_text and footnote_text != \" \":\n",
    "                    footnote_text = footnote_text.replace(\"\\n\", \" \")\n",
    "                    note_a_pie_di_pagina.append(footnote_text)\n",
    "\n",
    "\n",
    "            tabelle[table_key] = {\n",
    "                \"caption\": caption_text,\n",
    "                \"table\": dati_tabella,\n",
    "                \"footnotes\": note_a_pie_di_pagina,\n",
    "                \"references\": references_text,\n",
    "                }\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing figure in {file_path}: {e.with_traceback(None)}\")\n",
    "            logging.error(f\"Figure content: {etree.tostring(element, encoding='unicode', pretty_print=True)}\")\n",
    "\n",
    "    return tabelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Itera attraverso i file nella cartella 'articoli' e estrae le tabelle, didascalie, note e riferimenti\n",
    "total_tables = 0\n",
    "total_captions = 0\n",
    "total_footnotes = 0\n",
    "total_references = 0\n",
    "articolo_counter = 0\n",
    "\n",
    "#questo é perché nel salvataggio dei file ho creato cartella articoli dentro a sources\n",
    "for filename in os.listdir(SOURCES_DIR):\n",
    "    file_path = os.path.join(SOURCES_DIR, filename)\n",
    "    article_id = filename.split('_')[2].replace('.html', '')  # Estrae l'ID dal nome del file (primo elemento prima del punto)\n",
    "\n",
    "    articolo_counter += 1  # Incrementa il contatore\n",
    "    logging.info(f\"Estraendo dati dall'articolo {articolo_counter}: {filename}...\")\n",
    "\n",
    "    # Estrai i dati dal file HTML\n",
    "    dati_estratti = estrai_dati_da_file_v2(file_path)\n",
    "\n",
    "    # Update statistics counters\n",
    "    for table_data in dati_estratti.values():\n",
    "        total_tables += 1\n",
    "        if table_data[\"caption\"]:\n",
    "            total_captions += 1\n",
    "        total_footnotes += len(table_data[\"footnotes\"])\n",
    "        total_references += len(table_data[\"references\"])\n",
    "\n",
    "    # Salva i dati in JSON\n",
    "    salva_dati_in_json(dati_estratti, article_id, EXTRACTION_DIR)\n",
    "        \n",
    "# Print statistics\n",
    "logging.info(\"\\n--- Extraction Statistics ---\")\n",
    "logging.info(f\"Total Articles Processed: {articolo_counter}\")\n",
    "logging.info(f\"Total Tables Found: {total_tables}\")\n",
    "logging.info(f\"Total Captions Found: {total_captions}\")\n",
    "logging.info(f\"Total Footnotes Found: {total_footnotes}\")\n",
    "logging.info(f\"Total References Found: {total_references}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerazioni sui risultati ottenuti:\\\n",
    "Alcune tabelle non sono trovate mediante xpath, anche se esso è molto più selettivo e preciso del precedente, poiché i documenti HTML sono malformati (es.):\n",
    "* il documento 2405.15145 che ha la prima tabella separata dal tag `<figure>` \n",
    "* il documento 2310.02071 che costruisce una tabella attraverso il tag `<svg>` il quale è renderizzato con errori sul documento."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
