{
    "id_table_1": {
        "caption": "Table 1:Comparison for the mean precision of key point prediction in AntEval.",
        "table": [
            [],
            [
                "<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" id=\"S4.T1.1.1.4.2.2\">\n          55.93\n         </td>\n         ",
                "<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" id=\"S4.T1.1.1.4.2.3\">\n          60.40\n         </td>\n        "
            ]
        ],
        "footnotes": [],
        "references": [
            "In our informativeness evaluation, we compare the GPT-3.5 and GPT-4 models. These models act as characters in DND, generating interactions and responding to queries about the information they gather during these interactions. A summarization model is then used to summarize the responses into key points for comparison with predefined ground truths. We report the average precision of these key points in Tab                  1                . Our experiments show that the performance gap between the GPT-3.5 and GPT-4 models is modest. When GPT-3.5 serves as the summarization model, it slightly outperforms GPT-4 by                                   2.42                         %                                                 percent                            2.42                                       2.42\\%                       . In contrast, when GPT-4 is used as the summarization model, it outperforms GPT-3.5 by                                   4.47                         %                                                 percent                            4.47                                       4.47\\%                       , which is also relatively modest. These results lead to two key observations:1). Improving informativeness in agent interactions is challenging. All models, despite their advanced capabilities, struggle in this framework. Social interactions, which are typically more straightforward for humans and do not require extensive logical analysis or reasoning, pose a significant challenge to LLMs, highlighting their limitations in social interaction processing and pointing to areas for improvement.2). The performance gap between models of different capacities is not significant. Although GPT-4 is more advanced than GPT-3.5, it does not consistently outperform in every scenario. This suggests that current LLMs might not be fully optimized for long-context interactions and may lack the necessary capabilities for effective and informative expression. Interactions often tend to be conservative and repetitive, lacking the depth and richness of real-life human communication."
        ]
    },
    "id_table_2": {
        "caption": "Table 2:Comparison for the variances of prediction in AntEval.",
        "table": [
            [],
            [
                "<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" id=\"S4.T2.1.1.4.2.2\">\n          6.55\n         </td>\n         ",
                "<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" id=\"S4.T2.1.1.4.2.3\">\n          4.44\n         </td>\n        "
            ]
        ],
        "footnotes": [],
        "references": [
            "Additionally, as illustrated in Tab                  2                , we present the variances calculated for the matching precision of key points. Across all combinations of interaction models and summarization models, the variances are similar, indicating a consistent level of fluctuation in predictions and summarizations. Despite these fluctuations, the variances remain relatively stable, averaging around                                   5                         %                                                 percent                            5                                       5\\%                       . This stability suggests that our evaluation method is not only effective but also demonstrates a considerable degree of robustness. The consistency in variance across different model combinations reinforces the reliability of our approach in assessing the informativeness of agent interactions."
        ]
    },
    "id_table_3": {
        "caption": "Table 3:Comparison for the gaps between different models trained using real and generated interactions. GPT-3.5-lc represents the recently released long-context version. The metricf0subscriptùëì0f_{0}reflects results obtained using LLMs without fine-tuning. Metricsfrsubscriptùëìùëüf_{r}andfvsubscriptùëìùë£f_{v}denote results from LLMs fine-tuned with real interactions from human players and virtual interactions generated by agents, respectively.",
        "table": [
            [],
            [
                "<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" id=\"S4.T3.8.8.8.11.2.2\">\n          29.89\n         </td>\n         ",
                "<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" id=\"S4.T3.8.8.8.11.2.3\">\n          33.92\n         </td>\n         ",
                "<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" id=\"S4.T3.8.8.8.11.2.4\">\n          44.01\n         </td>\n         ",
                "<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" id=\"S4.T3.8.8.8.11.2.5\">\n          12.94\n         </td>\n         ",
                "<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" id=\"S4.T3.8.8.8.11.2.6\">\n          12.22\n         </td>\n         ",
                "<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" id=\"S4.T3.8.8.8.11.2.7\">\n          20.33\n         </td>\n         ",
                "<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" id=\"S4.T3.8.8.8.11.2.8\">\n          33.48\n         </td>\n         ",
                "<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t\" id=\"S4.T3.8.8.8.11.2.9\">\n          24.44\n         </td>\n        "
            ]
        ],
        "footnotes": [],
        "references": [
            "In expressiveness evaluation, we fine-tune LLMs using both real and generated interaction data. These models then construct virtual DMs and engage in the intention estimation task as in           Liang et¬†al. (             2023c            )          . As shown in Fig                  3                , we observe significant gap                          G                               ùê∫                              G                       in all settings, with values exceeding                                   12                         %                                                 percent                            12                                       12\\%                       . These high values of IEG indicates a marked difference between generated and real interactions, suggesting that real data provide more substantial insights than generated interactions. The F-score results offer additional detail, supporting this conclusion. Notably, models fine-tuned with real data consistently outperform those tuned with generated data. For example, GPT-3.5, when fine-tuned with real interactions, exceeds the performance of those fine-tuned with generated data by                                   10.45                         %                                                 percent                            10.45                                       10.45\\%                       and                                   20.49                         %                                                 percent                            20.49                                       20.49\\%                       in character and skill checks, respectively. This disparity underscores the importance of high-quality interactions for effective intention estimation. Given the difficulty in obtaining high-quality real-world interactions, our framework proves to be an essential tool for driving forward research into improving agent interactions. The significant disparity in skill checks, as opposed to character checks, further emphasizes the complexity of intention prediction and reinforces the notion that generated interactions lag behind real interactions in quality. LLMs appear to extract more meaningful information from real data.",
            "To offer a baseline for comparison, we introduce an additional evaluation metric,                                   f                         0                                                 subscript                            ùëì                            0                                       f_{0}                       , representing the performance of LLMs used to construct virtual agents directly, without fine-tuning, following the approach in           Liang et¬†al. (             2023c            )          . According to Tab                  3                ,                                   f                         0                                                 subscript                            ùëì                            0                                       f_{0}                       shows lower values compared to both                                   f                         v                                                 subscript                            ùëì                            ùë£                                       f_{v}                       and                                   f                         r                                                 subscript                            ùëì                            ùëü                                       f_{r}                       , indicating the usefulness of fine-tuning with additional data. However, given the higher quality of real interactions, learning from real human interactions proves to be more effective than using agent-generated interactions."
        ]
    }
}