{
    "id_table_1": {
        "caption": "Table 1:Comparison of Mobile-Bench with existing LLM-based agent platforms. ‘InfoUI’ represents whether UI information is used for interaction with agents, ‘API&UI’ represents whether the agent’s actions like API calls and UI interface operations, ’Real APP’ represents whether real applications are used, ‘Real Query’ represents whether real user queries are used, and ‘Multi-APP’ represents whether there are tasks involving multiple applications.",
        "table": [
            [
                "<td class=\"ltx_td ltx_align_left\" id=\"S1.T1.1.3.2.1\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n       WebShop\n       <cite class=\"ltx_cite ltx_citemacro_cite\">\n        Yao et al. (\n        <a class=\"ltx_ref\" href=\"#bib.bib45\" title=\"\">\n         2022\n        </a>\n        )\n       </cite>\n      </td>\n      ",
                "<td class=\"ltx_td ltx_align_center\" id=\"S1.T1.1.3.2.2\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n       ✓\n      </td>\n      ",
                "<td class=\"ltx_td ltx_align_center\" id=\"S1.T1.1.3.2.3\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n       ✗\n      </td>\n      ",
                "<td class=\"ltx_td ltx_align_center\" id=\"S1.T1.1.3.2.4\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n       ✗\n      </td>\n      ",
                "<td class=\"ltx_td ltx_align_center\" id=\"S1.T1.1.3.2.5\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n       ✗\n      </td>\n      ",
                "<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S1.T1.1.3.2.6\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n       ✗\n      </td>\n     "
            ],
            [
                "<td class=\"ltx_td ltx_align_left\" id=\"S1.T1.1.4.3.1\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n       AndroidEnv\n       <cite class=\"ltx_cite ltx_citemacro_cite\">\n        Toyama et al. (\n        <a class=\"ltx_ref\" href=\"#bib.bib40\" title=\"\">\n         2021\n        </a>\n        )\n       </cite>\n      </td>\n      ",
                "<td class=\"ltx_td ltx_align_center\" id=\"S1.T1.1.4.3.2\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n       ✗\n      </td>\n      ",
                "<td class=\"ltx_td ltx_align_center\" id=\"S1.T1.1.4.3.3\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n       ✗\n      </td>\n      ",
                "<td class=\"ltx_td ltx_align_center\" id=\"S1.T1.1.4.3.4\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n       ✓\n      </td>\n      ",
                "<td class=\"ltx_td ltx_align_center\" id=\"S1.T1.1.4.3.5\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n       ✗\n      </td>\n      ",
                "<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S1.T1.1.4.3.6\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n       ✗\n      </td>\n     "
            ],
            [
                "<td class=\"ltx_td ltx_align_left\" id=\"S1.T1.1.5.4.1\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n       MobileEnv\n       <cite class=\"ltx_cite ltx_citemacro_cite\">\n        Zhang et al. (\n        <a class=\"ltx_ref\" href=\"#bib.bib47\" title=\"\">\n         2023\n        </a>\n        )\n       </cite>\n      </td>\n      ",
                "<td class=\"ltx_td ltx_align_center\" id=\"S1.T1.1.5.4.2\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n       ✓\n      </td>\n      ",
                "<td class=\"ltx_td ltx_align_center\" id=\"S1.T1.1.5.4.3\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n       ✗\n      </td>\n      ",
                "<td class=\"ltx_td ltx_align_center\" id=\"S1.T1.1.5.4.4\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n       ✓\n      </td>\n      ",
                "<td class=\"ltx_td ltx_align_center\" id=\"S1.T1.1.5.4.5\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n       ✗\n      </td>\n      ",
                "<td class=\"ltx_td ltx_nopad_r ltx_align_center\" id=\"S1.T1.1.5.4.6\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n       ✗\n      </td>\n     "
            ],
            [
                "<td class=\"ltx_td ltx_align_left ltx_border_b ltx_border_t\" id=\"S1.T1.1.6.5.1\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n       <span class=\"ltx_text ltx_font_bold\" id=\"S1.T1.1.6.5.1.1\">\n        Mobile-Bench (Ours)\n       </span>\n      </td>\n      ",
                "<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\" id=\"S1.T1.1.6.5.2\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n       ✓\n      </td>\n      ",
                "<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\" id=\"S1.T1.1.6.5.3\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n       ✓\n      </td>\n      ",
                "<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\" id=\"S1.T1.1.6.5.4\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n       ✓\n      </td>\n      ",
                "<td class=\"ltx_td ltx_align_center ltx_border_b ltx_border_t\" id=\"S1.T1.1.6.5.5\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n       ✓\n      </td>\n      ",
                "<td class=\"ltx_td ltx_nopad_r ltx_align_center ltx_border_b ltx_border_t\" id=\"S1.T1.1.6.5.6\" style=\"padding-top:1pt;padding-bottom:1pt;\">\n       ✓\n      </td>\n     "
            ]
        ],
        "footnotes": [],
        "references": [
            "In fact, voice assistants on mobile phones can meet most of the users’ daily needs, yet they do not interact directly with UI interfaces but operate by invoking the APIs         Qin et al. (           2023          )        behind applications.As shown in Figure               1             , in mobile applications, APIs are more efficient than UI interfaces; a single API call can be equivalent to multiple UI operations to achieve the same outcome.However, a single API is insufficient for more complex tasks, especially when user commands are unclear, necessitating reliance on LLMs to interpret user intent. Therefore, an agent capable of utilizing both UI and APIs would be best suited for the job. Simultaneously, It requires developing a strategy for the selection and order of the application usage, with human oversight merely focusing on reviewing the outcomes. This is a function that voice assistants currently lack         Wen et al. (           2023a          ,           b          )        .To this end, we develop a combination of API and UI actions to circumvent the limitations of UI interfaces, each action can be chosen between UI interactions and API calls; all tasks begin from the mobile HOME page rather than from the launch page of a specific application, enabling the agent to determine single or multiple applications it will use; queries in the task are gathered from real users, and instruction generation is only applied to some complex ones which undergo rigorous manual review; we draw inspiration from objective metrics in software automation testing, named CheckPoint, and have made necessary adjustments to accommodate the unpredictable semantic outputs of LLMs.Above all, we propose a mobile phone environment that includes a platform supporting both API and UI interactions, and a corresponding dataset with multi-APP tasks.Table               1             presents a comparison among recent platforms and benchmark work based on API and UI."
        ]
    }
}